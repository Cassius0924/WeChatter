from typing import Dict, List
from urllib.parse import quote

import requests
from bs4 import BeautifulSoup
from loguru import logger

from wechatter.commands.handlers import command
from wechatter.exceptions import Bs4ParsingError
from wechatter.models.message import SendTo
from wechatter.sender import sender
from wechatter.utils import get_request


@command(
    command="food-calories",
    keys=["é£Ÿç‰©çƒ­é‡", "food-calories", "çƒ­é‡", "calories", "å¡è·¯é‡Œ"],
    desc="è·å–é£Ÿç‰©çƒ­é‡ã€‚",
)
def food_calories_command_handler(to: SendTo, message: str = "") -> None:
    try:
        result = get_food_calories_str(message)
    except Exception as e:
        error_message = f"è·å–é£Ÿç‰©çƒ­é‡å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{str(e)}"
        logger.error(error_message)
        sender.send_msg(to, error_message)
    else:
        sender.send_msg(to, result)


def get_food_calories_str(message: str) -> str:
    if not message:
        return "æŸ¥è¯¢å¤±è´¥ï¼Œè¯·è¾“å…¥é£Ÿç‰©åç§°"
    response = get_request(url=f"https://www.boohee.com/food/search?keyword={message}")
    food_href_list = _parse_food_href_list_response(response)
    food_detail_list = _get_food_detail_list(food_href_list)
    result = _generate_food_message(food_detail_list)
    return result


def _get_food_detail_list(food_href_list: List) -> List:
    """
    è·å–é£Ÿç‰©è¯¦æƒ…åˆ—è¡¨
    :param food_href_list: é£Ÿç‰©è¯¦æƒ…é“¾æ¥åˆ—è¡¨
    :return: é£Ÿç‰©è¯¦æƒ…åˆ—è¡¨
    """
    food_detail_list = []
    for i, food in enumerate(food_href_list[:5]):
        food_name = food.get("name")
        food_all_name = food.get("all_name")
        food_href = food.get("href")
        keyword = _get_url_encoding(food_name)  # è·å–URLç¼–ç 
        headers = {
            "referer": f"https://www.boohee.com/food/search?keyword={keyword}",
        }
        food_response = get_request(
            url=f"https://www.boohee.com{food_href}", headers=headers
        )
        if not food_response:
            logger.error(f"è·å–é£Ÿç‰©è¯¦æƒ…å¤±è´¥ï¼Œé£Ÿç‰©åç§°ï¼š{food_name}")
            raise ValueError(f"è·å–é£Ÿç‰©è¯¦æƒ…å¤±è´¥ï¼Œé£Ÿç‰©åç§°ï¼š{food_name}")
        food_detail = _parse_food_detail_response(food_response, food_all_name)
        food_detail_list.append(food_detail)
    if not food_detail_list:
        logger.error("è·å–é£Ÿç‰©è¯¦æƒ…å¤±è´¥,ä¸ºç©ºåˆ—è¡¨")
        raise ValueError("è·å–é£Ÿç‰©è¯¦æƒ…å¤±è´¥,ä¸ºç©ºåˆ—è¡¨")
    return food_detail_list


def _generate_food_message(food_detail_list: List) -> str:
    """
    ç”Ÿæˆé£Ÿç‰©ä¿¡æ¯
    :param food_detail_list: é£Ÿç‰©è¯¦æƒ…åˆ—è¡¨
    :return: é£Ÿç‰©ä¿¡æ¯
    """
    if not food_detail_list:
        logger.error("é£Ÿç‰©è¯¦æƒ…åˆ—è¡¨ä¸ºç©º")
        raise ValueError("é£Ÿç‰©è¯¦æƒ…åˆ—è¡¨ä¸ºç©º")
    food_str = "âœ¨=====é£Ÿç‰©åˆ—è¡¨=====âœ¨\n"

    for i, food_detail in enumerate(food_detail_list):
        energy = food_detail["çƒ­é‡(å¤§å¡)"]
        carbohydrate = food_detail["ç¢³æ°´åŒ–åˆç‰©(å…‹)"]
        fat = food_detail["è„‚è‚ª(å…‹)"]
        protein = food_detail["è›‹ç™½è´¨(å…‹)"]
        dietary_fiber = food_detail["çº¤ç»´ç´ (å…‹)"]
        food_all_name = food_detail["food_all_name"]
        food_str += (
            f"{i + 1}. {food_all_name}\n"
            f"    ğŸ²çƒ­é‡(å¤§å¡):    {energy}\n"
            f"    ğŸç¢³æ°´(å…‹):        {carbohydrate}\n"
            f"    ğŸ¥“è„‚è‚ª(å…‹):        {fat}\n"
            f"    ğŸ—è›‹ç™½è´¨(å…‹):    {protein}\n"
            f"    ğŸ¥¦çº¤ç»´ç´ (å…‹):    {dietary_fiber}\n"
        )
    food_str += "ğŸ”µ====å«é‡(100å…‹)====ğŸ”µ"

    return food_str


# è¿™é‡Œä¹Ÿæ˜¯ parseéƒ¨åˆ†
def _parse_food_detail_response(
    response: requests.Response, food_all_name: str
) -> Dict:
    """
    è§£æé£Ÿç‰©è¯¦æƒ…
    :param response: è¯·æ±‚å“åº”
    :param food_all_name: é£Ÿç‰©å…¨å
    :return: é£Ÿç‰©è¯¦æƒ…
    """
    soup = BeautifulSoup(response.text, "html.parser")
    food_detail = {}
    articles = soup.find_all("dd")
    for article in articles:
        name = article.select_one("span.dt").text.strip()
        value = article.select_one("span.dd").text.strip()
        if name and value:
            food_detail[name] = value
    if not food_detail:
        logger.error("è§£æé£Ÿç‰©åˆ—è¡¨å¤±è´¥")
        raise Bs4ParsingError("è§£æé£Ÿç‰©åˆ—è¡¨å¤±è´¥")

    food_detail["food_all_name"] = food_all_name
    return food_detail


def _parse_food_href_list_response(response: requests.Response) -> List:
    """
    è§£æé£Ÿç‰©è¯¦æƒ…é“¾æ¥åˆ—è¡¨
    :param response: è¯·æ±‚å“åº”
    :return: é£Ÿç‰©è¯¦æƒ…é“¾æ¥åˆ—è¡¨
    """
    soup = BeautifulSoup(response.text, "html.parser")
    href_list = []
    articles = soup.select("div.text-box")
    if not articles:
        logger.error("è§£æé£Ÿç‰©è¯¦æƒ…é“¾æ¥å¤±è´¥")
        raise Bs4ParsingError("è§£æé£Ÿç‰©è¯¦æƒ…é“¾æ¥å¤±è´¥")
    for article in articles:
        href_list_item = {}

        name = article.select_one("a").text.strip()
        if name:
            href_list_item["name"] = name.split("ï¼Œ")[0]
            href_list_item["all_name"] = name
        href = article.a["href"]
        if href:
            href_list_item["href"] = href

        if href_list_item:
            href_list.append(href_list_item)

    if not href_list:
        logger.error("è§£æé£Ÿç‰©è¯¦æƒ…é“¾æ¥å¤±è´¥")
        raise Bs4ParsingError("è§£æé£Ÿç‰©è¯¦æƒ…é“¾æ¥å¤±è´¥")

    return href_list


def _get_url_encoding(message: str) -> str:
    """
    è·å–URLç¼–ç 
    :param message: æ¶ˆæ¯
    :return: URLç¼–ç 
    """
    url_encoding = quote(message)
    return url_encoding
